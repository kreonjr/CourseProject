# Text Cleaning & Topic Mining

## Overview

The scripts present here perform data cleaning on the web scraped data made available in the collect_data folder and then proceed to perform LDA Topic Mining and analysis.

## Requirements

The scripts were tested and run in an Anaconda Python 3.8.8 virtual environment.

Python packages used:
* pandas 1.2.4
* regex 2021.4.4
* nltk 3.6.1
  * import stopwords
  * import wordpunt_tokenize
  * import WordNetLemmatizer
* gensim 4.1.2
  * import gensim.corpora
  * import LdaModel
  * import CoherenceModel
* pyLDAvis 3.3.1
* matplotlib 3.3.4

## Scripts

### `text_cleaning.py`

Takes the scraped content from the forked github projects that are stored in python/collect_data/project_text.tsv and performs a series of data cleaning steps on it.
This script makes all the content lower case,removes punctuations and digits, tokenizes, lemmatizes and also removes high frequency words which are not considered as high value words for tag creation.

#### Output

* `project_clean_text.tsv`: tab-delimited file of project URLs, filenames,text harvested from those files and list of tokens produced from the text. One row per project file.

### `LDA.py`

Takes the tokens generated by above script and runs the LDA algorithm on it to produce a number of topics. Each topic is then matched against a CS410 project based on the highest probability match. The number of topics are decdied after a thorough study on the LDA model, this study is done in python/text_mining/topic_model_eval.ipynb. 

#### Output

* `AlgOutput.tsv`: tab-delimited file of project URLs, filenames, text harvested from those files,list of tokens produced from the text and list of words/tags identified from the highest probability topic.One row per project file.
* `firebase-output.json`: JSON output that is used by web api and firebase to create the front end.

### `topic_model_eval.ipynb`

Jupyter notebook that provides a guided walkthrough of the script in LDA.py and follows up with a detailed study on which would be the best fit number of topics based on Coherence and perplexity. It also used the pyLDAvis library to help with this study.

